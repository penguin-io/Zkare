//! Entity 1: ZK Proof Service
//!
//! This service implements the data holder and zero-knowledge proof generator
//! as described in the paper. It securely processes user data and generates
//! cryptographic proofs of user traits without revealing the underlying data.

use anyhow::{Context, Result};
use axum::{
    extract::{Path, Query, State},
    http::{HeaderMap, StatusCode},
    response::Json,
    routing::{get, post},
    Router,
};
use base64::{engine::general_purpose, Engine as _};
use chrono::{DateTime, Utc};
use risc0_zkvm::{default_prover, ExecutorEnv};
use serde::{Deserialize, Serialize};
use sha2::{Digest, Sha256};
use sqlx::{PgPool, Row};
use std::{collections::HashMap, sync::Arc, time::Instant};
use tokio::net::TcpListener;
use tower::ServiceBuilder;
use tower_http::{cors::CorsLayer, trace::TraceLayer};
use tracing::{info, warn, error, instrument};
use uuid::Uuid;

// Include the guest code generated by the build script
risc0_zkvm::include_image!("guest");

/// Application state shared across handlers
#[derive(Clone)]
pub struct AppState {
    pub db: PgPool,
    pub redis: redis::aio::ConnectionManager,
    pub config: Arc<Config>,
}

/// Configuration structure
#[derive(Debug, Clone)]
pub struct Config {
    pub server_port: u16,
    pub database_url: String,
    pub redis_url: String,
    pub max_proof_cache_ttl: u64,
    pub enable_gpu: bool,
    pub rate_limit_per_minute: u32,
}

/// User profile input for risk assessment
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct UserRiskProfile {
    pub age: u32,
    pub income: u64,
    pub savings: u64,
    pub has_mortgage: bool,
    pub has_retirement_plan: bool,
    pub investment_experience: InvestmentExperience,
    pub risk_questions: [u8; 10],
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum InvestmentExperience {
    Beginner = 1,
    Intermediate = 2,
    Advanced = 3,
}

/// Request structure for proof generation
#[derive(Debug, Deserialize)]
pub struct ProofGenerationRequest {
    pub user_data: UserRiskProfile,
    pub inference_type: InferenceType,
    pub user_id: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum InferenceType {
    FinancialRisk,
    HealthRisk,
    PersonalityAssessment,
}

/// Response structure for proof generation
#[derive(Debug, Serialize)]
pub struct ProofGenerationResponse {
    pub proof_id: String,
    pub verified_traits: VerifiedTraits,
    pub proof_data: String, // Base64 encoded proof
    pub verification_key: String,
    pub generated_at: DateTime<Utc>,
    pub expires_at: DateTime<Utc>,
}

/// Verified traits that can be shared with Entity 2
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct VerifiedTraits {
    pub risk_category: RiskCategory,
    pub confidence_score: u32,
    pub age_bracket: AgeBracket,
    pub income_level: IncomeLevel,
    pub experience_level: ExperienceLevel,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum RiskCategory {
    Conservative = 1,
    SteadyGrowth = 2,
    Balanced = 3,
    AggressiveInvestment = 4,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum AgeBracket {
    Young,      // 18-35
    MiddleAge,  // 36-50
    Mature,     // 51-65
    Senior,     // 66+
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum IncomeLevel {
    Low,        // < 50k
    Medium,     // 50k-100k
    High,       // 100k-200k
    VeryHigh,   // 200k+
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ExperienceLevel {
    Beginner,
    Intermediate,
    Advanced,
}

/// Proof verification request
#[derive(Debug, Deserialize)]
pub struct ProofVerificationRequest {
    pub proof_id: String,
    pub proof_data: String,
    pub verification_key: String,
}

/// Proof verification response
#[derive(Debug, Serialize)]
pub struct ProofVerificationResponse {
    pub is_valid: bool,
    pub verified_traits: Option<VerifiedTraits>,
    pub verification_time_ms: u64,
}

/// Health check response
#[derive(Debug, Serialize)]
pub struct HealthResponse {
    pub status: String,
    pub version: String,
    pub uptime_seconds: u64,
    pub database_connected: bool,
    pub redis_connected: bool,
}

/// Statistics response
#[derive(Debug, Serialize)]
pub struct StatsResponse {
    pub total_proofs_generated: i64,
    pub total_verifications: i64,
    pub average_proof_time_ms: f64,
    pub cache_hit_rate: f64,
}

static START_TIME: std::sync::OnceLock<Instant> = std::sync::OnceLock::new();

#[tokio::main]
async fn main() -> Result<()> {
    // Initialize tracing
    tracing_subscriber::fmt()
        .with_env_filter(
            tracing_subscriber::EnvFilter::from_default_env()
                .add_directive("zkproof_service=info".parse()?)
        )
        .json()
        .init();

    START_TIME.set(Instant::now()).ok();

    info!("Starting ZK Proof Service (Entity 1)");

    // Load configuration
    let config = load_config().context("Failed to load configuration")?;
    info!("Configuration loaded successfully");

    // Initialize database connection
    let db = PgPool::connect(&config.database_url)
        .await
        .context("Failed to connect to database")?;

    // Run database migrations
    sqlx::migrate!("./migrations")
        .run(&db)
        .await
        .context("Failed to run database migrations")?;

    info!("Database connected and migrations applied");

    // Initialize Redis connection
    let redis_client = redis::Client::open(config.redis_url.clone())
        .context("Failed to create Redis client")?;
    let redis = redis::aio::ConnectionManager::new(redis_client)
        .await
        .context("Failed to connect to Redis")?;

    info!("Redis connected successfully");

    // Create application state
    let state = AppState {
        db,
        redis,
        config: Arc::new(config.clone()),
    };

    // Build the router
    let app = create_router(state);

    // Start the server
    let listener = TcpListener::bind(format!("0.0.0.0:{}", config.server_port))
        .await
        .context("Failed to bind to address")?;

    info!("Server listening on port {}", config.server_port);

    axum::serve(listener, app)
        .await
        .context("Server error")?;

    Ok(())
}

fn create_router(state: AppState) -> Router {
    Router::new()
        .route("/health", get(health_check))
        .route("/stats", get(get_stats))
        .route("/generate-proof", post(generate_proof))
        .route("/verify-proof", post(verify_proof))
        .route("/proof/:proof_id", get(get_proof))
        .layer(
            ServiceBuilder::new()
                .layer(TraceLayer::new_for_http())
                .layer(CorsLayer::permissive())
        )
        .with_state(state)
}

/// Health check endpoint
#[instrument(skip(state))]
async fn health_check(State(state): State<AppState>) -> Result<Json<HealthResponse>, StatusCode> {
    let uptime = START_TIME
        .get()
        .map(|start| start.elapsed().as_secs())
        .unwrap_or(0);

    // Check database connection
    let db_connected = sqlx::query("SELECT 1")
        .fetch_one(&state.db)
        .await
        .is_ok();

    // Check Redis connection
    let redis_connected = {
        let mut conn = state.redis.clone();
        redis::cmd("PING")
            .query_async::<_, String>(&mut conn)
            .await
            .is_ok()
    };

    let response = HealthResponse {
        status: if db_connected && redis_connected {
            "healthy".to_string()
        } else {
            "degraded".to_string()
        },
        version: env!("CARGO_PKG_VERSION").to_string(),
        uptime_seconds: uptime,
        database_connected: db_connected,
        redis_connected,
    };

    Ok(Json(response))
}

/// Get service statistics
#[instrument(skip(state))]
async fn get_stats(State(state): State<AppState>) -> Result<Json<StatsResponse>, StatusCode> {
    let total_proofs: i64 = sqlx::query_scalar("SELECT COUNT(*) FROM proofs")
        .fetch_one(&state.db)
        .await
        .unwrap_or(0);

    let total_verifications: i64 = sqlx::query_scalar("SELECT COUNT(*) FROM verifications")
        .fetch_one(&state.db)
        .await
        .unwrap_or(0);

    let avg_proof_time: f64 = sqlx::query_scalar(
        "SELECT AVG(generation_time_ms) FROM proofs WHERE generation_time_ms IS NOT NULL"
    )
    .fetch_one(&state.db)
    .await
    .unwrap_or(0.0);

    // Calculate cache hit rate from Redis
    let cache_hit_rate = calculate_cache_hit_rate(&state).await.unwrap_or(0.0);

    let response = StatsResponse {
        total_proofs_generated: total_proofs,
        total_verifications,
        average_proof_time_ms: avg_proof_time,
        cache_hit_rate,
    };

    Ok(Json(response))
}

/// Generate zero-knowledge proof for user traits
#[instrument(skip(state, request))]
async fn generate_proof(
    State(state): State<AppState>,
    Json(request): Json<ProofGenerationRequest>,
) -> Result<Json<ProofGenerationResponse>, StatusCode> {
    let start_time = Instant::now();
    let proof_id = Uuid::new_v4().to_string();

    info!("Generating proof {} for inference type {:?}", proof_id, request.inference_type);

    // Check rate limiting
    if let Err(_) = check_rate_limit(&state, &request.user_id).await {
        warn!("Rate limit exceeded for user {:?}", request.user_id);
        return Err(StatusCode::TOO_MANY_REQUESTS);
    }

    match generate_zk_proof(&state, &request, &proof_id).await {
        Ok(response) => {
            let generation_time = start_time.elapsed().as_millis() as i64;

            // Store proof metadata in database
            if let Err(e) = store_proof_metadata(&state, &proof_id, &request, generation_time).await {
                error!("Failed to store proof metadata: {}", e);
            }

            info!("Proof {} generated successfully in {}ms", proof_id, generation_time);
            Ok(Json(response))
        }
        Err(e) => {
            error!("Failed to generate proof {}: {}", proof_id, e);
            Err(StatusCode::INTERNAL_SERVER_ERROR)
        }
    }
}

/// Verify a zero-knowledge proof
#[instrument(skip(state, request))]
async fn verify_proof(
    State(state): State<AppState>,
    Json(request): Json<ProofVerificationRequest>,
) -> Result<Json<ProofVerificationResponse>, StatusCode> {
    let start_time = Instant::now();

    info!("Verifying proof {}", request.proof_id);

    match verify_zk_proof(&state, &request).await {
        Ok(response) => {
            let verification_time = start_time.elapsed().as_millis();

            // Log verification attempt
            if let Err(e) = log_verification(&state, &request.proof_id, verification_time as i64).await {
                warn!("Failed to log verification: {}", e);
            }

            info!("Proof {} verified in {}ms", request.proof_id, verification_time);
            Ok(Json(ProofVerificationResponse {
                verification_time_ms: verification_time,
                ..response
            }))
        }
        Err(e) => {
            error!("Failed to verify proof {}: {}", request.proof_id, e);
            Err(StatusCode::BAD_REQUEST)
        }
    }
}

/// Get proof details by ID
#[instrument(skip(state))]
async fn get_proof(
    State(state): State<AppState>,
    Path(proof_id): Path<String>,
) -> Result<Json<ProofGenerationResponse>, StatusCode> {
    match retrieve_proof(&state, &proof_id).await {
        Ok(Some(proof)) => Ok(Json(proof)),
        Ok(None) => Err(StatusCode::NOT_FOUND),
        Err(e) => {
            error!("Failed to retrieve proof {}: {}", proof_id, e);
            Err(StatusCode::INTERNAL_SERVER_ERROR)
        }
    }
}

/// Generate the actual zero-knowledge proof using RiscZero
async fn generate_zk_proof(
    state: &AppState,
    request: &ProofGenerationRequest,
    proof_id: &str,
) -> Result<ProofGenerationResponse> {
    // Check cache first
    if let Ok(Some(cached_proof)) = get_cached_proof(state, request).await {
        info!("Returning cached proof for request");
        return Ok(cached_proof);
    }

    // Create the prover environment
    let env = ExecutorEnv::builder()
        .write(&request.user_data)?
        .build()?;

    // Generate the proof
    let prover = default_prover();
    let receipt = prover.prove(env, GUEST_ELF)?;

    // Verify the proof locally to ensure it's valid
    receipt.verify(GUEST_ID)?;

    // Extract the result from the proof
    let result: crate::guest::RiskAssessmentResult = receipt.journal.decode()?;

    // Convert to verified traits format
    let verified_traits = convert_to_verified_traits(&result, &request.user_data);

    // Encode proof and verification key
    let proof_data = general_purpose::STANDARD.encode(&receipt.inner.flat().unwrap());
    let verification_key = general_purpose::STANDARD.encode(GUEST_ID);

    let now = Utc::now();
    let expires_at = now + chrono::Duration::hours(24); // 24-hour expiry

    let response = ProofGenerationResponse {
        proof_id: proof_id.to_string(),
        verified_traits: verified_traits.clone(),
        proof_data,
        verification_key,
        generated_at: now,
        expires_at,
    };

    // Cache the proof
    if let Err(e) = cache_proof(state, request, &response).await {
        warn!("Failed to cache proof: {}", e);
    }

    Ok(response)
}

/// Verify a zero-knowledge proof
async fn verify_zk_proof(
    _state: &AppState,
    request: &ProofVerificationRequest,
) -> Result<ProofVerificationResponse> {
    // Decode the proof and verification key
    let proof_data = general_purpose::STANDARD.decode(&request.proof_data)?;
    let expected_image_id = general_purpose::STANDARD.decode(&request.verification_key)?;

    // Verify that the verification key matches our guest program
    if expected_image_id != GUEST_ID {
        return Ok(ProofVerificationResponse {
            is_valid: false,
            verified_traits: None,
            verification_time_ms: 0,
        });
    }

    // TODO: Implement full proof verification using RiscZero
    // For now, we'll do a basic validation
    let is_valid = !proof_data.is_empty() && proof_data.len() > 32;

    Ok(ProofVerificationResponse {
        is_valid,
        verified_traits: None, // Would extract from verified proof
        verification_time_ms: 0,
    })
}

/// Convert guest program result to verified traits
fn convert_to_verified_traits(
    result: &crate::guest::RiskAssessmentResult,
    profile: &UserRiskProfile,
) -> VerifiedTraits {
    let age_bracket = match profile.age {
        18..=35 => AgeBracket::Young,
        36..=50 => AgeBracket::MiddleAge,
        51..=65 => AgeBracket::Mature,
        _ => AgeBracket::Senior,
    };

    let income_level = match profile.income {
        0..=49_999 => IncomeLevel::Low,
        50_000..=99_999 => IncomeLevel::Medium,
        100_000..=199_999 => IncomeLevel::High,
        _ => IncomeLevel::VeryHigh,
    };

    let experience_level = match profile.investment_experience {
        InvestmentExperience::Beginner => ExperienceLevel::Beginner,
        InvestmentExperience::Intermediate => ExperienceLevel::Intermediate,
        InvestmentExperience::Advanced => ExperienceLevel::Advanced,
    };

    VerifiedTraits {
        risk_category: match result.risk_category {
            crate::guest::RiskCategory::Conservative => RiskCategory::Conservative,
            crate::guest::RiskCategory::SteadyGrowth => RiskCategory::SteadyGrowth,
            crate::guest::RiskCategory::Balanced => RiskCategory::Balanced,
            crate::guest::RiskCategory::AggressiveInvestment => RiskCategory::AggressiveInvestment,
        },
        confidence_score: result.confidence_score,
        age_bracket,
        income_level,
        experience_level,
    }
}

/// Check rate limiting for a user
async fn check_rate_limit(state: &AppState, user_id: &Option<String>) -> Result<()> {
    let key = format!("rate_limit:{}", user_id.as_deref().unwrap_or("anonymous"));
    let mut conn = state.redis.clone();

    let current_count: i32 = redis::cmd("INCR")
        .arg(&key)
        .query_async(&mut conn)
        .await
        .unwrap_or(1);

    if current_count == 1 {
        // Set expiry on first request
        let _: () = redis::cmd("EXPIRE")
            .arg(&key)
            .arg(60) // 60 seconds
            .query_async(&mut conn)
            .await?;
    }

    if current_count > state.config.rate_limit_per_minute as i32 {
        return Err(anyhow::anyhow!("Rate limit exceeded"));
    }

    Ok(())
}

/// Cache a generated proof
async fn cache_proof(
    state: &AppState,
    request: &ProofGenerationRequest,
    response: &ProofGenerationResponse,
) -> Result<()> {
    let cache_key = generate_cache_key(request);
    let cache_value = serde_json::to_string(response)?;

    let mut conn = state.redis.clone();
    let _: () = redis::cmd("SETEX")
        .arg(cache_key)
        .arg(state.config.max_proof_cache_ttl)
        .arg(cache_value)
        .query_async(&mut conn)
        .await?;

    Ok(())
}

/// Get cached proof if available
async fn get_cached_proof(
    state: &AppState,
    request: &ProofGenerationRequest,
) -> Result<Option<ProofGenerationResponse>> {
    let cache_key = generate_cache_key(request);
    let mut conn = state.redis.clone();

    let cached_value: Option<String> = redis::cmd("GET")
        .arg(cache_key)
        .query_async(&mut conn)
        .await?;

    match cached_value {
        Some(value) => Ok(Some(serde_json::from_str(&value)?)),
        None => Ok(None),
    }
}

/// Generate cache key for a request
fn generate_cache_key(request: &ProofGenerationRequest) -> String {
    let mut hasher = Sha256::new();
    hasher.update(serde_json::to_string(request).unwrap_or_default());
    let hash = hasher.finalize();
    format!("proof_cache:{}", hex::encode(hash))
}

/// Store proof metadata in database
async fn store_proof_metadata(
    state: &AppState,
    proof_id: &str,
    request: &ProofGenerationRequest,
    generation_time_ms: i64,
) -> Result<()> {
    sqlx::query!(
        r#"
        INSERT INTO proofs (proof_id, inference_type, user_id, generation_time_ms, created_at)
        VALUES ($1, $2, $3, $4, NOW())
        "#,
        proof_id,
        serde_json::to_string(&request.inference_type)?,
        request.user_id,
        generation_time_ms
    )
    .execute(&state.db)
    .await?;

    Ok(())
}

/// Log verification attempt
async fn log_verification(
    state: &AppState,
    proof_id: &str,
    verification_time_ms: i64,
) -> Result<()> {
    sqlx::query!(
        r#"
        INSERT INTO verifications (proof_id, verification_time_ms, verified_at)
        VALUES ($1, $2, NOW())
        "#,
        proof_id,
        verification_time_ms
    )
    .execute(&state.db)
    .await?;

    Ok(())
}

/// Retrieve proof from database
async fn retrieve_proof(
    state: &AppState,
    proof_id: &str,
) -> Result<Option<ProofGenerationResponse>> {
    // This would typically retrieve from database and reconstruct the response
    // For now, return None as this would require storing the full proof data
    Ok(None)
}

/// Calculate cache hit rate
async fn calculate_cache_hit_rate(state: &AppState) -> Result<f64> {
    // This would calculate based on Redis statistics
    // For now, return a placeholder value
    Ok(0.75)
}

/// Load configuration from environment variables
fn load_config() -> Result<Config> {
    Ok(Config {
        server_port: std::env::var("PORT")
            .unwrap_or_else(|_| "8001".to_string())
            .parse()?,
        database_url: std::env::var("DATABASE_URL")
            .unwrap_or_else(|_| "postgres://zkp_user:zkp_secure_password@postgres:5432/zkp_llm".to_string()),
        redis_url: std::env::var("REDIS_URL")
            .unwrap_or_else(|_| "redis://redis:6379".to_string()),
        max_proof_cache_ttl: std::env::var("CACHE_TTL")
            .unwrap_or_else(|_| "3600".to_string())
            .parse()?,
        enable_gpu: std::env::var("ENABLE_GPU")
            .unwrap_or_else(|_| "true".to_string())
            .parse()?,
        rate_limit_per_minute: std::env::var("RATE_LIMIT")
            .unwrap_or_else(|_| "10".to_string())
            .parse()?,
    })
}

// Re-export guest types for use in main
mod guest {
    pub use super::super::guest::*;
}
